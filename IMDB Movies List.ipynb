{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Movies list scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red\">**Sometimes TimeoutError will occur because of the list of the movies in particular year, re-run the code again with proper network speed. Or Server problem</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAMIL MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Year: 2021\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#creating a variables to store the values\n",
    "\n",
    "pages, movie_name, movie_link, year = [], [], [], []\n",
    "duration, genre, rating = [], [], []\n",
    "description, director, actors = [],[], []\n",
    "page_number, names = [], []\n",
    "\n",
    "release_year = int(input(\"Enter the Year: \"))\n",
    "\n",
    "url =(\"https://www.imdb.com/search/title/?title_type=feature&year={0}-01-01,{0}-12-31&languages=ta&sort=release_date,asc&explore=languages\").format(release_year)\n",
    "res = requests.get(url)\n",
    "ht = res.text\n",
    "sp = BeautifulSoup(ht,\"html.parser\")\n",
    "pa = sp.find(\"div\", {\"class\": \"desc\"})\n",
    "pg = pa.span.text.replace(\" titles.\",\"\")\n",
    "\n",
    "#calculating the number of page\n",
    "\n",
    "if \" of \" in pg:\n",
    "    try:\n",
    "        x = pg.split(\" of \")\n",
    "        x = int(x[1])\n",
    "        x = math.ceil(x/50)\n",
    "        x = x * 50\n",
    "        page_number.append(x)\n",
    "    except:\n",
    "        print(\"try\")\n",
    "else:\n",
    "    x = 50\n",
    "    page_number.append(x)\n",
    "\n",
    "#getting all the URL of the required page\n",
    "\n",
    "for i in range(1, page_number[0], 50):\n",
    "    new_url = (\"https://www.imdb.com/search/title/?title_type=feature&year={0}-01-01,{0}-12-31&languages=ta&sort=release_date,asc&start={1}&explore=languages\").format(release_year,i)\n",
    "    pages.append(new_url)\n",
    "\n",
    "#scraping all the required data\n",
    "\n",
    "for item in pages:\n",
    "    page = requests.get(item)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    data = soup.findAll(\"div\", attrs= {\"class\" : \"lister-item mode-advanced\"})\n",
    "    for store in data:\n",
    "        name = store.h3.a.text\n",
    "        movie_name.append(name)\n",
    "        \n",
    "        link = store.h3.a.get('href')\n",
    "        l = \"https://www.imdb.com\" + link\n",
    "        movie_link.append(l)\n",
    "\n",
    "        #y = store.h3.find(\"span\", attrs= {\"class\" : \"lister-item-year text-muted unbold\"}).text.replace('(','').replace(')','').replace('I ','').replace('II ','')\n",
    "        y = release_year\n",
    "        year.append(y)\n",
    "\n",
    "        t = store.p.find(\"span\", attrs= {\"class\" : \"runtime\"}).text.replace(' min','') if store.p.find(\"span\", attrs= {\"class\" : \"runtime\"}) else 'NA'\n",
    "        duration.append(t)\n",
    "\n",
    "        g = store.p.find(\"span\", attrs= {\"class\" : \"genre\"}).text.replace('\\n','').strip() if store.p.find(\"span\", attrs= {\"class\" : \"genre\"}) else 'NA'\n",
    "        genre.append(g)\n",
    "\n",
    "        r = store.find(\"div\", attrs= {\"class\" : \"inline-block ratings-imdb-rating\"}).text.replace('\\n','') if store.find(\"div\", attrs= {\"class\" : \"inline-block ratings-imdb-rating\"}) else 'NA'\n",
    "        rating.append(r)\n",
    "\n",
    "        des = store.find_all(\"p\", attrs= {\"class\": \"text-muted\"}) if store.find_all(\"p\", attrs= {\"class\": \"text-muted\"}) else 'NA'\n",
    "        d = des[1].text.replace('\\n','').replace('Add a Plot','NA').replace('..                See full summary\\xa0»','').strip()\n",
    "        description.append(d)\n",
    "\n",
    "        stars = store.find_all(\"p\")\n",
    "        n = stars[2].text.replace('\\n','').replace('|','').strip().split('     ')\n",
    "        names.append(n)\n",
    "\n",
    "for i in names:\n",
    "    try:\n",
    "        director.append(i[0].replace(\"Director:\", \"\").replace(\"Directors:\", \"\"))\n",
    "    except:\n",
    "        director.append(\"NA\")\n",
    "    try:\n",
    "        actors.append(i[1].replace(\"Star:\", \"\").replace(\"Stars:\", \"\"))\n",
    "    except:\n",
    "        actors.append(\"NA\")\n",
    "\n",
    "variables = {\"title\": movie_name, \"title_link\": movie_link, \"year\": year, \"duration\": duration, \"genre\": genre, \n",
    "             \"description\": description, \"director\": director, \"actors\": actors, \"rating\": rating}\n",
    "\n",
    "file = (\"{}_ta.csv\").format(release_year)\n",
    "\n",
    "#creating the dataframe\n",
    "\n",
    "df = pd.DataFrame(variables)\n",
    "\n",
    "df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute this inorder to combine all CSV files in one single CSV file\n",
    "\n",
    "all_filenames = []\n",
    "j = 1995\n",
    "for i in range(15):\n",
    "    j = 1980 + i\n",
    "    fd = \"{}_ta.csv\".format(j)\n",
    "    all_filenames.append(fd)   \n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "\n",
    "#export to csv\n",
    "combined_csv.to_csv(\"combined_csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute this inorder to remove rows which has VA values\n",
    "\n",
    "df1 = pd.read_csv(\"combined_csv.csv\")\n",
    "features = [\"movie_id\",\"actors\", \"director\", \"genre\", \"title\"]\n",
    "df2 = df1[features].dropna()\n",
    "final_file = df1.merge(df2, how='inner')\n",
    "final_file.to_csv(\"imdb_tamil.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute this to fill empty cell\n",
    "\n",
    "df3 = pd.read_csv(\"imdb_tamil.csv\")\n",
    "features = [\"movie_id\",\"description\"]\n",
    "df4 = final_file[features].fillna(\"NA\")\n",
    "file = df3.merge(df4, how='inner')\n",
    "data = file.fillna('NA')\n",
    "data.to_csv(\"imdb_tamil_movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENGLISH MOVIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a variables to store the values\n",
    "\n",
    "pages, movie_name, movie_link, year = [], [], [], []\n",
    "duration, genre, rating = [], [], []\n",
    "description, director, actors = [],[], []\n",
    "names = []\n",
    "\n",
    "release_year = int(input(\"Enter the Year: \"))\n",
    "\n",
    "page_number = 2 * 50\n",
    "\n",
    "#getting all the URL of the required page\n",
    "\n",
    "for i in range(1, page_number, 50):\n",
    "    new_url = (\"https://www.imdb.com/search/title/?title_type=feature&year={0}-01-01,{0}-12-31&start={1}&ref_=adv_nxt\").format(release_year,i)\n",
    "    pages.append(new_url)\n",
    "\n",
    "#scraping all the required data\n",
    "\n",
    "for item in pages:\n",
    "    page = requests.get(item)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    data = soup.findAll(\"div\", attrs= {\"class\" : \"lister-item mode-advanced\"})\n",
    "    for store in data:\n",
    "        name = store.h3.a.text\n",
    "        movie_name.append(name)\n",
    "        \n",
    "        link = store.h3.a.get('href')\n",
    "        l = \"https://www.imdb.com\" + link\n",
    "        movie_link.append(l)\n",
    "\n",
    "        #y = store.h3.find(\"span\", attrs= {\"class\" : \"lister-item-year text-muted unbold\"}).text.replace('(','').replace(')','').replace('I ','').replace('II ','')\n",
    "        y = release_year\n",
    "        year.append(y)\n",
    "\n",
    "        t = store.p.find(\"span\", attrs= {\"class\" : \"runtime\"}).text.replace(' min','') if store.p.find(\"span\", attrs= {\"class\" : \"runtime\"}) else 'NA'\n",
    "        duration.append(t)\n",
    "\n",
    "        g = store.p.find(\"span\", attrs= {\"class\" : \"genre\"}).text.replace('\\n','').strip() if store.p.find(\"span\", attrs= {\"class\" : \"genre\"}) else 'NA'\n",
    "        genre.append(g)\n",
    "\n",
    "        r = store.find(\"div\", attrs= {\"class\" : \"inline-block ratings-imdb-rating\"}).text.replace('\\n','') if store.find(\"div\", attrs= {\"class\" : \"inline-block ratings-imdb-rating\"}) else 'NA'\n",
    "        rating.append(r)\n",
    "\n",
    "        des = store.find_all(\"p\", attrs= {\"class\": \"text-muted\"}) if store.find_all(\"p\", attrs= {\"class\": \"text-muted\"}) else 'NA'\n",
    "        d = des[1].text.replace('\\n','').replace('Add a Plot','NA').replace('..                See full summary\\xa0»','').strip()\n",
    "        description.append(d)\n",
    "\n",
    "        stars = store.find_all(\"p\")\n",
    "        n = stars[2].text.replace('\\n','').replace('|','').strip().split('     ')\n",
    "        names.append(n)\n",
    "\n",
    "for i in names:\n",
    "    try:\n",
    "        director.append(i[0].replace(\"Director:\", \"\").replace(\"Directors:\", \"\"))\n",
    "    except:\n",
    "        director.append(\"NA\")\n",
    "    try:\n",
    "        actors.append(i[1].replace(\"Star:\", \"\").replace(\"Stars:\", \"\"))\n",
    "    except:\n",
    "        actors.append(\"NA\")\n",
    "\n",
    "variables = {\"title\": movie_name, \"title_link\": movie_link, \"year\": year, \"duration\": duration, \"genre\": genre, \n",
    "             \"description\": description, \"director\": director, \"actors\": actors, \"rating\": rating}\n",
    "\n",
    "file = (\"{}_en.csv\").format(release_year)\n",
    "\n",
    "#creating the dataframe\n",
    "\n",
    "df = pd.DataFrame(variables)\n",
    "\n",
    "df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute this inorder to combine all CSV files in one single CSV file\n",
    "\n",
    "all_filenames = []\n",
    "for i in range(7):\n",
    "    j = 1981 + i\n",
    "    fd = \"{}_en.csv\".format(j)\n",
    "    all_filenames.append(fd)\n",
    "    \n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "\n",
    "#export to csv\n",
    "combined_csv.to_csv(\"combined_csv.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
